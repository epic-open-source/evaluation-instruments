{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31ca555-18fe-4383-b9f0-86189831d126",
   "metadata": {},
   "source": [
    "## Configuring Your Foundation Model with the OpenAI Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59b46a-6fe4-432f-b62a-461cbfd701de",
   "metadata": {},
   "source": [
    "This section outlines how to configure your foundation model using the OpenAI Python library. This library provides a standardized and convenient way to interact with OpenAI's REST API from Python 3.8+ applications.\n",
    "\n",
    "#### Leveraging the OpenAI Python Library ####\n",
    "\n",
    "Instead of relying on a custom setup, we recommend using the official OpenAI Python library for interacting with OpenAI models. This library offers:\n",
    "\n",
    "- Type Definitions: Includes type definitions for all request parameters and response fields.\n",
    "- Synchronous and Asynchronous Clients: Provides both synchronous and asynchronous clients powered by httpx.\n",
    "- Standardized Interface: Offers a consistent and well-documented interface for interacting with various OpenAI models.\n",
    "\n",
    "#### Installation ####\n",
    "\n",
    "Install the library using pip:\n",
    "\n",
    "pip install openai\n",
    "\n",
    "#### Usage: Chat Completions API ####\n",
    "\n",
    "The Chat Completions API is the recommended way to generate text from the model. Here's a basic example:\n",
    "\n",
    "```\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",  # Replace with your desired model\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Your prompt here.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "```\n",
    "\n",
    "\n",
    "#### Key Components for Evaluation ####\n",
    "\n",
    "For the evaluation framework to function correctly, the completion object returned by the client.chat.completions.create() method needs to provide the following information:\n",
    "\n",
    "- completion.choices[0].message.content: This attribute contains the text generated by the model. The evaluation framework expects this to be the primary output.\n",
    "- completion.usage: This attribute contains usage statistics. The evaluation framework may use the total_tokens, completion_tokens, and prompt_tokens keys within completion.usage for limiting or tracking resource consumption during evaluation.\n",
    "\n",
    "#### Configuration Notes ####\n",
    "\n",
    "- Authentication: The OpenAI Python library handles authentication using API keys. Ensure you have set your API key as an environment variable (OPENAI_API_KEY) or configure it directly when initializing the OpenAI client. Refer to the OpenAI documentation for details on authentication.\n",
    "- Model Selection: The model parameter in the client.chat.completions.create() method specifies the model to use. Choose the appropriate model for your evaluation task.\n",
    "- Customization: The client.chat.completions.create() method accepts various parameters for customizing the model's behavior, such as temperature, top_p, and frequency_penalty. Refer to the OpenAI API documentation for a complete list of available parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1f698-99d6-4082-aadc-e37770bbd96c",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c2343",
   "metadata": {},
   "source": [
    "Here we load a dummy data that is presented as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7114ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bvg228/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noteid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient ID: Bertha James is a 78-year-old fema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinical Note:\\n\\nAssessment of Bertha James, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    notes\n",
       "noteid                                                   \n",
       "0       Patient ID: Bertha James is a 78-year-old fema...\n",
       "1       Clinical Note:\\n\\nAssessment of Bertha James, ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "notes = {\"notes\": {\n",
    "        \"1\": \"Patient ID: Bertha James is a 78-year-old female.\\n\\nShe came into the office complaining of vaginal bleeding. Additional concerns were raised due to her recent, seemingly unexplainable weight loss.\\n\\n\\nMs. Bertha is otherwise normally healthy for her age but has been demonstrating symptoms of nutritional deficiency. \\n\\n\\nUpon examination, vaginal bleeding is present. The patient appears frail, her weight is less than her average, raising concerns regarding her nutrition and well-being.\\n\\n\\nThe main concern is her vaginal bleeding and unusual weight loss in addition to her overall physical state. We will start by ordering a laboratory workup to better understand the source of the post-menopausal vaginal bleeding including hormonal profile, INR study, and endometrial biopsy. A dietician consultation will be made to assess her nutritional status as her weight loss is concerning. \\n\\nFurthermore, to ensure her comprehensive care, she has been advised to check with a Psychiatrist for her reported acute insomnia and anxiety, an Orthopedic practitioner for her new-onset hip fracture, and a Dermatologist for proper treatment of her untreated skin fungal infection. Regardless, given the suspicious circumstances surrounding her rapidly changing health status, a report for potential elder abuse will be filed and legal consultation will be sought to ensure the patient's needs and rights are being maintained. \\n\\n\",\n",
    "        \"2\": \"Clinical Note:\\n\\nAssessment of Bertha James, 78-year-old female patient, continues to reveal alarming signs that necessitate further attention and evaluation. Primary concerns originated from her initial consultation for vaginal bleeding and subsequent uncovering of atypical weight loss. Soon after, Bertha revealed signs of insomnia and anxiety putting her mental health in question. Instances of physical harm, notably a hip fracture and a fungal infection which remained untreated, are highly suggestive of elder abuse. Previous assessments indicate a suspected lack of proper care adding fuel to these speculations. Legal intervention has been proposed following these observed signs in relation to possible senior abuse. It is crucial that we put in place enhanced measures to ensure Bertha's welfare and safety. Closure and resolution to these troubling indications are paramount to her overall wellbeing. Her caregivers, medical and mental health, need to provide extensive and multidimensional care moving forward.\",\n",
    " }}\n",
    "\n",
    "input_df = pd.DataFrame(notes)\n",
    "input_df.index = [i for i in range(input_df.shape[0])]\n",
    "input_df.index.name = \"noteid\"\n",
    "\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dfa11-3257-46d3-9269-59584842d56e",
   "metadata": {},
   "source": [
    "## Setting up the instrument and Running the Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d86156-6aa4-4d7b-b23f-f0bb24b01cfb",
   "metadata": {},
   "source": [
    "The run_pipeline function provides a convenient way to evaluate a dataset using different pre-defined prompt categories. It encapsulates the entire evaluation process, handling prompt creation, model completion, and result aggregation behind the scenes.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "**1. Input Requirements:** The run_pipeline function requires two arguments:\n",
    "\n",
    "- `input_df`: A pandas DataFrame containing the data to be evaluated.  Each row of the DataFrame represents a single data point to be processed.\n",
    "- `completion`: The model completion function as indicated above. This function takes a model and a prompt (a list of messages) as input and returns the model's raw output.  This function is responsible for interacting with the language model.\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. Prompt Selection:** The function iterates through a dictionary of prompt categories (e.g., \"complete\", \"clinical_reasoning\"). Each category is associated with a specific prompt creation function (e.g., create_complete_prompt). These prompt creation functions are designed to be compatible with the input data format. Selection of a pre-formed prompt is done via these prompt creation functions.\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Evaluation Initialization:** For each prompt category, an Evaluation instance is created. This instance is initialized with:\n",
    "\n",
    "   - completion_fn: The model completion function.\n",
    "   - prep_fn: The prompt creation function for the current category. This function takes a namedtuple representing a single row from the input DataFrame (obtained via pandas.DataFrame.itertuples) and transforms it into a messages array suitable for the completion_fn.\n",
    "   - log_enabled: A flag to enable logging of raw model outputs. If True, raw outputs are saved to evaluation/logs/raw_content_&lt;TIMESTAMP&gt;.jsonl.\n",
    "   - max_tokens: An optional token limit to abort the evaluation loop if exceeded. Default: 80_000\n",
    "    \n",
    "<br>\n",
    "\n",
    "**4. Dataset Evaluation:** The evaluator.run_dataset function is called with the input DataFrame. This function performs the core evaluation loop, processing the DataFrame row by row. Behind the scenes, run_dataset performs the following steps for each row:\n",
    "\n",
    "   - prompt = prep_fn(namedtuple[dataframe itertuples]): The prompt is generated using the prep_fn (prompt creation function) and a namedtuple representing the current row of the DataFrame.\n",
    "   - raw_output = completion_fn(model, prompt): The generated prompt is passed to the completion_fn (model completion function) to obtain the model's raw output.\n",
    "   - response, usage = post_process_fn(raw_output): The raw output is processed by a post_process_fn (defaulting to extracting a single completion and attempting to parse it as JSON). This function extracts the relevant information from the model's response (e.g., the completion text) and returns it along with token usage information.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Result Aggregation:** The run_dataset function returns a dictionary where keys are 'noteid's (presumably from the input DataFrame) and values are the parsed completion results (or whatever the first output of the post_process_fn returns). The run_pipeline function aggregates these results across all prompt categories. For each note, it creates a dictionary containing the evaluation grades for each category. Thus, each note is graded for each of the categories.\n",
    "\n",
    "<br>\n",
    "\n",
    "**6. Output:** The run_pipeline function returns a dictionary where keys are 'noteid's and values are dictionaries containing the evaluation grades for each category (e.g., {&#039;noteid1&#039;: {&#039;complete&#039;: 1, &#039;clinical_assessment_reasoning&#039;: 0, ...}})."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa4c8d",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757d8a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running evaluation for: complete ---\n",
      "\n",
      "--- Running evaluation for: clinical_assessment_reasoning ---\n",
      "\n",
      "--- Running evaluation for: contingent ---\n",
      "\n",
      "--- Running evaluation for: concise ---\n",
      "\n",
      "--- Running evaluation for: correct ---\n"
     ]
    }
   ],
   "source": [
    "from run_5cs_pipeline import run_pipeline\n",
    "graded_dict = run_pipeline(input_df, completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8fbee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'complete': 1,\n",
       "  'clinical_assessment_reasoning': 1,\n",
       "  'contingent': 0,\n",
       "  'concise': 1,\n",
       "  'correct': 1},\n",
       " 1: {'complete': 0,\n",
       "  'clinical_assessment_reasoning': 1,\n",
       "  'contingent': 0,\n",
       "  'concise': 1,\n",
       "  'correct': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc89902f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complete</th>\n",
       "      <th>clinical_assessment_reasoning</th>\n",
       "      <th>contingent</th>\n",
       "      <th>concise</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complete  clinical_assessment_reasoning  contingent  concise  correct\n",
       "0         1                              1           0        1        1\n",
       "1         0                              1           0        1        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_df = pd.DataFrame.from_dict(graded_dict, orient='index')\n",
    "graded_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
