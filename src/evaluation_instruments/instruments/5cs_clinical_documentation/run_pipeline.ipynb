{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31ca555-18fe-4383-b9f0-86189831d126",
   "metadata": {},
   "source": [
    "## Configuring Your Foundation Model with the OpenAI Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59b46a-6fe4-432f-b62a-461cbfd701de",
   "metadata": {},
   "source": [
    "Setting up your foundation model is beyond the scope of this repository, as there is not a unified method.  \n",
    "We lean on the protocol used by <ins>[LiteLLM chat completions](https://docs.litellm.ai/docs/completion)</ins> as it provides a consistent method for interacting with a wide variety of providers.  It also makes things \"look like\" OpenAI so it is expected to need minimal adaptation for a majority of usecases.\n",
    "\n",
    "Configuration will usually involve specifying how to make authorized calls to your model, so will most frequently be setting secrets in keys and possibly specifying custom urls.\n",
    "\n",
    "The evaluation framework expects parts from both ends of a completion function.  <br/>\n",
    "The <ins>[completion function](https://docs.litellm.ai/docs/completion/input)</ins> should be callable and support input arguments of a model specifier, messages array (list of dicts with user+content), and any provider specific configuration.<br/>\n",
    "Currently two pieces of the <ins>[output json](https://docs.litellm.ai/docs/completion/output)</ins> are expected:  \n",
    "\n",
    "- `response['choices'][0]['message']['content']` should be the text of the completion\n",
    "- `response['usage']` should whichever keys in total_tokens, completion_tokens, and prompt_tokens that you might want to limit for an evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1f698-99d6-4082-aadc-e37770bbd96c",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c2343",
   "metadata": {},
   "source": [
    "Here we load a dummy data that is presented as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7114ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noteid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient ID: Bertha James is a 78-year-old fema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinical Note:\\n\\nAssessment of Bertha James, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    notes\n",
       "noteid                                                   \n",
       "0       Patient ID: Bertha James is a 78-year-old fema...\n",
       "1       Clinical Note:\\n\\nAssessment of Bertha James, ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "notes = {\"notes\": {\n",
    "        \"1\": \"Patient ID: Bertha James is a 78-year-old female.\\n\\nShe came into the office complaining of vaginal bleeding. Additional concerns were raised due to her recent, seemingly unexplainable weight loss.\\n\\n\\nMs. Bertha is otherwise normally healthy for her age but has been demonstrating symptoms of nutritional deficiency. \\n\\n\\nUpon examination, vaginal bleeding is present. The patient appears frail, her weight is less than her average, raising concerns regarding her nutrition and well-being.\\n\\n\\nThe main concern is her vaginal bleeding and unusual weight loss in addition to her overall physical state. We will start by ordering a laboratory workup to better understand the source of the post-menopausal vaginal bleeding including hormonal profile, INR study, and endometrial biopsy. A dietician consultation will be made to assess her nutritional status as her weight loss is concerning. \\n\\nFurthermore, to ensure her comprehensive care, she has been advised to check with a Psychiatrist for her reported acute insomnia and anxiety, an Orthopedic practitioner for her new-onset hip fracture, and a Dermatologist for proper treatment of her untreated skin fungal infection. Regardless, given the suspicious circumstances surrounding her rapidly changing health status, a report for potential elder abuse will be filed and legal consultation will be sought to ensure the patient's needs and rights are being maintained. \\n\\n\",\n",
    "        \"2\": \"Clinical Note:\\n\\nAssessment of Bertha James, 78-year-old female patient, continues to reveal alarming signs that necessitate further attention and evaluation. Primary concerns originated from her initial consultation for vaginal bleeding and subsequent uncovering of atypical weight loss. Soon after, Bertha revealed signs of insomnia and anxiety putting her mental health in question. Instances of physical harm, notably a hip fracture and a fungal infection which remained untreated, are highly suggestive of elder abuse. Previous assessments indicate a suspected lack of proper care adding fuel to these speculations. Legal intervention has been proposed following these observed signs in relation to possible senior abuse. It is crucial that we put in place enhanced measures to ensure Bertha's welfare and safety. Closure and resolution to these troubling indications are paramount to her overall wellbeing. Her caregivers, medical and mental health, need to provide extensive and multidimensional care moving forward.\",\n",
    " }}\n",
    "\n",
    "input_df = pd.DataFrame(notes)\n",
    "input_df.index = [i for i in range(input_df.shape[0])]\n",
    "input_df.index.name = \"noteid\"\n",
    "\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dfa11-3257-46d3-9269-59584842d56e",
   "metadata": {},
   "source": [
    "## Setting up the instrument and Running the Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d86156-6aa4-4d7b-b23f-f0bb24b01cfb",
   "metadata": {},
   "source": [
    "The run_pipeline function provides a convenient way to evaluate a dataset using different pre-defined prompt categories. It encapsulates the entire evaluation process, handling prompt creation, model completion, and result aggregation behind the scenes.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "**1. Input Requirements:** The run_pipeline function requires two arguments:\n",
    "\n",
    "- input_df (pd.DataFrame): The pandas DataFrame containing the data to be evaluated. It must include a 'noteid' column, which is used to uniquely identify each data point in the final output. Other columns should contain the text and information required by the prompt creation functions.\n",
    "\n",
    "- completion: The model completion function. This function takes a model name and a list of messages as input and returns the model's raw output, which is expected to be a JSON string.\n",
    "\n",
    "- log_enabled (bool): A flag to enable or disable logging of raw model outputs. When set to True, raw outputs are saved to evaluation/logs/raw_content_<TIMESTAMP>.jsonl.\n",
    "\n",
    "- max_tokens (int): An optional token limit to abort the evaluation loop if exceeded. The default is 80_000.\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. Prompt Selection:** The function iterates through a dictionary of prompt categories (e.g., \"complete\", \"clinical_reasoning\"). Each category is associated with a specific prompt creation function (e.g., create_complete_prompt). These prompt creation functions are designed to be compatible with the input data format. Selection of a pre-formed prompt is done via these prompt creation functions.\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Evaluation Initialization:** For each prompt category, an Evaluation instance is created. This instance is initialized with:\n",
    "\n",
    "   - completion_fn: The model completion function.\n",
    "   - prep_fn: The prompt creation function for the current category. This function takes a namedtuple representing a single row from the input DataFrame (obtained via pandas.DataFrame.itertuples) and transforms it into a messages array suitable for the completion_fn.\n",
    "   - log_enabled: A flag to enable logging of raw model outputs. If True, raw outputs are saved to evaluation/logs/raw_content_&lt;TIMESTAMP&gt;.jsonl.\n",
    "   - max_tokens: An optional token limit to abort the evaluation loop if exceeded. Default: 80_000\n",
    "   - log_prefix: A unique log_prefix is also set for each category to help organize the logs.\n",
    "    \n",
    "<br>\n",
    "\n",
    "**4. Dataset Evaluation:** The evaluator.run_dataset function is called with the input DataFrame. This function performs the core evaluation loop, processing the DataFrame row by row. Behind the scenes, run_dataset performs the following steps for each row:\n",
    "\n",
    "   - prompt = prep_fn(namedtuple[dataframe itertuples]): The prompt is generated using the prep_fn (prompt creation function) and a namedtuple representing the current row of the DataFrame.\n",
    "   - raw_output = completion_fn(model, prompt): The generated prompt is passed to the completion_fn (model completion function) to obtain the model's raw output.\n",
    "   - response, usage = post_process_fn(raw_output): The raw output is processed by a post_process_fn (defaulting to extracting a single completion and attempting to parse it as JSON). This function extracts the relevant information from the model's response (e.g., the completion text) and returns it along with token usage information.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Result Aggregation:** The run_dataset function returns a dictionary where keys are 'noteid's (presumably from the input DataFrame) and values are the parsed completion results (or whatever the first output of the post_process_fn returns). The run_pipeline function aggregates these results across all prompt categories. For each note, it creates a dictionary containing the evaluation grades for each category. Thus, each note is graded for each of the categories.\n",
    "\n",
    "<br>\n",
    "\n",
    "**6. Output:** The run_pipeline function returns a dictionary where keys are 'noteid's and values are dictionaries containing the evaluation grades for each category (e.g., {&#039;noteid1&#039;: {&#039;complete&#039;: 1, &#039;clinical_assessment_reasoning&#039;: 0, ...}})."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa4c8d",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "757d8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_5cs_pipeline import run_pipeline\n",
    "graded_dict = run_pipeline(input_df, completion, log_enabled = True, max_tokens = 80_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8fbee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'complete': 0,\n",
       "  'clinical_assessment_reasoning': 1,\n",
       "  'contingent': 0,\n",
       "  'concise': 1,\n",
       "  'correct': 0},\n",
       " 1: {'complete': 0,\n",
       "  'clinical_assessment_reasoning': 0,\n",
       "  'contingent': 0,\n",
       "  'concise': 1,\n",
       "  'correct': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc89902f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complete</th>\n",
       "      <th>clinical_assessment_reasoning</th>\n",
       "      <th>contingent</th>\n",
       "      <th>concise</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complete  clinical_assessment_reasoning  contingent  concise  correct\n",
       "0         0                              1           0        1        0\n",
       "1         0                              0           0        1        0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_df = pd.DataFrame.from_dict(graded_dict, orient='index')\n",
    "graded_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
